# Phase 46 Plan 01: Data Population Pipeline

---
phase: 46-data-population-pipeline
plan: 01
type: execute
---

<objective>
Run scraper for priority series, implement data validation, and execute initial P0 population with monitoring.

Purpose: Populate the coin reference database with ~835 P0 coins (bullion and key classics) to validate the pipeline before larger runs.
Output: P0 coins populated, validation passing, pipeline ready for P1-P3.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase context:
@.planning/phases/45-bulk-scraper-enhancement/45-01-SUMMARY.md
@.planning/phases/44-series-priority-mapping/SCRAPING-ROADMAP.md

# Key files from Phase 45:
@bullion-tracker/coin_scraper/run_scraper.py
@bullion-tracker/coin_scraper/scrapers/progress_tracker.py
@bullion-tracker/coin_scraper/scrapers/pcgs_scraper.py
@bullion-tracker/coin_scraper/config.py

**Tech stack available:** httpx, SQLite progress tracking, tqdm, circuit breaker
**Established patterns:** Selector fallback chains, exponential backoff, progress resume

**Constraining decisions:**
- Phase 45: SQLite for progress tracking (lightweight, file-based)
- Phase 44: 4-tier priority system (P0-P3)
- Phase 44: Hybrid API + scraping approach

**From SCRAPING-ROADMAP Phase 46 Requirements:**
1. Batch processing: Process series in priority order
2. Incremental updates: Track what's been scraped, support resume
3. Logging: Detailed logs for monitoring progress
4. Validation: Post-scrape data quality checks
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Population Runner with Monitoring</name>
  <files>bullion-tracker/coin_scraper/populate.py</files>
  <action>
Create a population orchestration script that:
1. Runs scraping by priority tier (P0 first, then P1, P2, P3)
2. Uses ProgressTracker from Phase 45 for resume capability
3. Logs progress to both console and file (logs/population_YYYY-MM-DD.log)
4. Generates end-of-run report with:
   - Coins scraped per series
   - Failure rates
   - Time elapsed
   - Database counts before/after
5. Supports --priority flag to run specific tier
6. Supports --dry-run to simulate without DB writes
7. Adds QuotaTracker integration for API-aware rate limiting

Use existing run_scraper.py infrastructure but add orchestration layer.
  </action>
  <verify>
python bullion-tracker/coin_scraper/populate.py --help shows options
python bullion-tracker/coin_scraper/populate.py --dry-run --priority P0 --limit 3 runs without errors
  </verify>
  <done>
- Population script runs with progress logging
- Supports --priority, --dry-run, --limit flags
- Generates timestamped log files
- End-of-run summary displayed
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Data Validation Module</name>
  <files>bullion-tracker/coin_scraper/validators/coin_validator.py</files>
  <action>
Create validation module for scraped coin data:
1. Create validators/ directory with __init__.py
2. Implement CoinValidator class with methods:
   - validate_required_fields(coin_data): Check pcgsNumber, year, series, fullName present
   - validate_year_range(year): 1793 <= year <= current_year + 1
   - validate_pcgs_number(num): Positive integer, reasonable range
   - validate_denomination(denom): Known denominations list
   - validate_mint_mark(mm): Valid mint mark or None
3. Add validate_batch(coins) method returning (valid, invalid) lists
4. Add ValidationReport class for aggregating validation results
5. Log validation failures with coin details for debugging
  </action>
  <verify>
python -c "from validators.coin_validator import CoinValidator; v = CoinValidator(); print(v.validate_required_fields({'pcgsNumber': 1234}))"
  </verify>
  <done>
- CoinValidator class with all validation methods
- ValidationReport for batch validation results
- Validation failures logged with details
  </done>
</task>

<task type="auto">
  <name>Task 3: Execute P0 Population Run</name>
  <files>bullion-tracker/coin_scraper/logs/</files>
  <action>
Execute the P0 population to validate the pipeline:
1. Create logs/ directory if not exists
2. Run: python populate.py --priority P0
3. Monitor progress via ProgressTracker
4. Capture and review the end-of-run report
5. Query database to verify coin counts:
   - SELECT series, COUNT(*) FROM "CoinReference" GROUP BY series;
6. Document results in logs/P0_population_results.md:
   - Start/end times
   - Coins per series
   - Success/failure rates
   - Any issues encountered
7. If scraping fails (403s, etc.), document gracefully - this is expected behavior since PCGS may block scrapers

Note: The actual scraping may take 10-30 minutes for P0 (~835 coins at 2/min).
If rate limited or blocked, capture partial results and document.
  </action>
  <verify>
ls bullion-tracker/coin_scraper/logs/population_*.log shows log file created
python -c "from config import DATABASE_URL; from sqlalchemy import create_engine, text; e = create_engine(DATABASE_URL); print(e.execute(text('SELECT COUNT(*) FROM \"CoinReference\"')).scalar())"
  </verify>
  <done>
- P0 population attempted (may be partial if rate limited)
- Log file generated with detailed progress
- Results documented in P0_population_results.md
- Database shows increased coin count (or baseline if blocked)
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] populate.py script runs with --help
- [ ] CoinValidator validates required fields correctly
- [ ] P0 population attempted with results documented
- [ ] Log files generated in logs/ directory
- [ ] Progress tracker shows series status
</verification>

<success_criteria>

- All tasks completed
- Population pipeline operational
- Data validation in place
- P0 results documented (success or blocked status)
- Ready for P1-P3 runs when rate limiting permits
</success_criteria>

<output>
After completion, create `.planning/phases/46-data-population-pipeline/46-01-SUMMARY.md`:

# Phase 46 Plan 01: Data Population Pipeline Summary

**[Substantive one-liner describing outcome]**

## Accomplishments
- [Key outcomes]

## Files Created/Modified
- `bullion-tracker/coin_scraper/populate.py` - Population orchestrator
- `bullion-tracker/coin_scraper/validators/coin_validator.py` - Data validation
- `bullion-tracker/coin_scraper/logs/` - Population logs

## Decisions Made
[Any decisions and rationale]

## Issues Encountered
[Problems and resolutions, or "None"]

## Next Phase Readiness
[Ready for Phase 47 or notes on P1-P3 runs]

---
*Phase: 46-data-population-pipeline*
*Plan: 01*
</output>

# Phase 47 Plan 01: Price Refresh Automation

---
phase: 47-price-refresh-automation
plan: 01
type: execute
---

<objective>
Create automated price refresh system using PCGS API with daily quota tracking and scheduled execution.

Purpose: Keep coin price guide values current without manual intervention.
Output: Python script for daily price refresh, Vercel Cron configuration, logging and reporting.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase context:
@.planning/phases/43-pcgs-api-integration/43-01-SUMMARY.md
@.planning/phases/46-data-population-pipeline/46-01-SUMMARY.md

# Key files from Phase 43:
@bullion-tracker/coin_scraper/api/pcgs_api.py
@bullion-tracker/coin_scraper/api/quota_tracker.py

# Existing price sync endpoint:
@bullion-tracker/src/app/api/collection/sync-prices/route.ts

**Tech stack available:** httpx, SQLAlchemy, PCGSApiClient with OAuth2, QuotaTracker
**Established patterns:** Async API client, daily quota tracking, JSON persistence

**Constraining decisions:**
- Phase 43: PCGS API with 1,000 free queries/day
- Phase 46: PCGS web scraping blocked - API-first approach required
- Next.js app uses Prisma, Python scraper uses SQLAlchemy

**Key insight from Phase 46:**
PCGS web scraping is blocked. This phase must use PCGS API exclusively for price updates.
With 1,000 calls/day and ~100 coins currently (eventually ~8,000), we need smart batching.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Price Refresh Script Using PCGS API</name>
  <files>bullion-tracker/coin_scraper/refresh_prices.py</files>
  <action>
Create a Python script that:
1. Connects to PostgreSQL database (same DATABASE_URL as scraper)
2. Queries CoinReference table for coins needing price update:
   - Filter: No CoinPriceGuide entry for today OR entry is >7 days old
   - Order by: Priority series first (P0, P1, P2, P3), then last update date
   - Limit: Based on remaining daily API quota
3. For each coin:
   - Use PCGSApiClient.get_coin_by_pcgs_and_grade() for common grades (MS65, MS66, MS67, PR70)
   - Parse response to extract prices
   - Upsert into CoinPriceGuide table
   - Track success/failure counts
4. Generate end-of-run report:
   - Coins updated
   - API calls used
   - Remaining quota
   - Next run estimate
5. CLI flags:
   - --dry-run: Check what would be updated without calling API
   - --limit N: Override calculated limit
   - --priority P0: Only update specific priority
   - --status: Show last run stats and quota

Use existing PCGSApiClient and QuotaTracker from api/ module.
Respect 1,000/day quota by calculating: remaining_quota / days_in_week = daily_budget.
  </action>
  <verify>
python bullion-tracker/coin_scraper/refresh_prices.py --help shows options
python bullion-tracker/coin_scraper/refresh_prices.py --status shows quota
python bullion-tracker/coin_scraper/refresh_prices.py --dry-run shows coins that would be updated
  </verify>
  <done>
- Price refresh script runs with all CLI flags
- Respects API quota limits
- Updates CoinPriceGuide table
- Generates run report
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Vercel Cron Configuration for Scheduled Refresh</name>
  <files>bullion-tracker/vercel.json, bullion-tracker/src/app/api/cron/refresh-prices/route.ts</files>
  <action>
Create a Vercel Cron endpoint for automated price refresh:

1. Create API route `src/app/api/cron/refresh-prices/route.ts`:
   - Verify CRON_SECRET header (Vercel sends this)
   - Call Python script via child_process.exec OR
   - Implement simplified price refresh directly in TypeScript using PCGS API
   - Return JSON with results

2. Update/create `vercel.json` with cron configuration:
```json
{
  "crons": [{
    "path": "/api/cron/refresh-prices",
    "schedule": "0 6 * * *"  // Daily at 6 AM UTC
  }]
}
```

3. Add CRON_SECRET to environment variables (for security)

Note: Vercel Cron has 10-second execution limit on free tier.
For longer operations, the endpoint should trigger the Python script
via a separate worker or just update a batch of highest-priority coins.

Alternative approach (simpler): Make the TypeScript endpoint update
only 10-20 highest-priority coins per run, using PCGS API directly.
  </action>
  <verify>
vercel.json has valid cron configuration
curl -H "Authorization: Bearer $CRON_SECRET" localhost:3000/api/cron/refresh-prices returns JSON
  </verify>
  <done>
- Cron endpoint created and secured
- vercel.json configured for daily schedule
- Test run succeeds locally
  </done>
</task>

<task type="auto">
  <name>Task 3: Add Price Refresh Logging and Reporting</name>
  <files>bullion-tracker/coin_scraper/logs/price_refresh_*.log, bullion-tracker/coin_scraper/data/price_refresh_history.json</files>
  <action>
Enhance the refresh script with comprehensive logging:

1. Create logs/ directory entry for each run:
   - Filename: price_refresh_YYYY-MM-DD.log
   - Format: timestamp, level, coin PCGS#, action, result
   - Track: API calls, successes, failures, quota

2. Create data/price_refresh_history.json to track:
   - Last run timestamp
   - Coins updated per run (last 30 runs)
   - Error trends
   - Average API calls per run

3. Add --report flag to show:
   - Last 7 days of refresh activity
   - Coins not updated in >14 days
   - Quota usage trends
   - Estimated time to full database refresh

4. Create summary markdown after each run:
   - logs/price_refresh_latest.md with human-readable summary
  </action>
  <verify>
ls bullion-tracker/coin_scraper/logs/price_refresh_*.log shows log files
python refresh_prices.py --report shows activity summary
  </verify>
  <done>
- Detailed logging to timestamped files
- History tracking in JSON
- Report command shows activity summary
- latest.md summary generated after each run
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] refresh_prices.py runs with --help, --status, --dry-run
- [ ] API quota respected (check quota_tracker before/after)
- [ ] Vercel cron configuration valid
- [ ] Logs generated in logs/ directory
- [ ] History tracked in price_refresh_history.json
</verification>

<success_criteria>

- All tasks completed
- Price refresh script operational with quota management
- Vercel cron configured for daily execution
- Logging and reporting in place
- Ready for Phase 48 (Search & Validation)
</success_criteria>

<output>
After completion, create `.planning/phases/47-price-refresh-automation/47-01-SUMMARY.md`:

# Phase 47 Plan 01: Price Refresh Automation Summary

**[Substantive one-liner describing outcome]**

## Accomplishments
- [Key outcomes]

## Files Created/Modified
- `bullion-tracker/coin_scraper/refresh_prices.py` - Price refresh script
- `bullion-tracker/vercel.json` - Cron configuration
- `bullion-tracker/src/app/api/cron/refresh-prices/route.ts` - Cron endpoint
- `bullion-tracker/coin_scraper/logs/` - Refresh logs

## Decisions Made
[Any decisions and rationale]

## Issues Encountered
[Problems and resolutions, or "None"]

## Next Phase Readiness
[Ready for Phase 48 or notes on search optimization]

---
*Phase: 47-price-refresh-automation*
*Plan: 01*
</output>
